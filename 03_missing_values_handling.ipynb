{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311350e4",
   "metadata": {},
   "source": [
    "# 🛠️ Adventurer Mart: ML Data Preparation - Part 3\n",
    "\n",
    "## 🔍 3. Missing Values Handling\n",
    "\n",
    "This notebook systematically identifies and handles missing values across all tables.\n",
    "\n",
    "### 🎯 Objectives\n",
    "- Analyze missing value patterns and causes\n",
    "- Implement appropriate missing value strategies\n",
    "- Validate handling effectiveness\n",
    "- Export cleaned data for next phase\n",
    "\n",
    "### 🔧 Handling Strategies\n",
    "- **Drop**: Remove columns/rows with excessive missing data\n",
    "- **Impute**: Fill missing values with statistical measures\n",
    "- **Flag**: Create indicator variables for missingness\n",
    "- **Advanced**: Use domain knowledge for context-specific handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5d7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Libraries imported successfully!\n",
      "🔧 Missing value handling tools ready\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📦 Libraries imported successfully!\")\n",
    "print(\"🔧 Missing value handling tools ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39469c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 LOADING DATA FROM PHASE 2\n",
      "==================================================\n",
      "✅ Loaded dataframes from Phase 2\n",
      "✅ Loaded EDA analysis results\n",
      "\n",
      "📊 Dataset Status:\n",
      "   • Tables: 9\n",
      "   • Total missing values: 474\n"
     ]
    }
   ],
   "source": [
    "# Load data from previous phase\n",
    "print(\"📂 LOADING DATA FROM PHASE 2\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load dataframes\n",
    "    with open('data_intermediate/02_dataframes.pkl', 'rb') as f:\n",
    "        dataframes = pickle.load(f)\n",
    "    print(\"✅ Loaded dataframes from Phase 2\")\n",
    "    \n",
    "    # Load EDA results\n",
    "    with open('data_intermediate/02_eda_results.pkl', 'rb') as f:\n",
    "        eda_results = pickle.load(f)\n",
    "    print(\"✅ Loaded EDA analysis results\")\n",
    "    \n",
    "    print(f\"\\n📊 Dataset Status:\")\n",
    "    print(f\"   • Tables: {len(dataframes)}\")\n",
    "    print(f\"   • Total missing values: {eda_results['summary_stats']['total_missing']:,}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    print(\"🔄 Please run previous phases first\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36237c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 MISSING VALUE PATTERN ANALYSIS\n",
      "============================================================\n",
      "\n",
      "📋 Table: details_adventure_gear\n",
      "----------------------------------------\n",
      "🕳️ Total missing values: 1\n",
      "📊 Columns with missing values: 1\n",
      "   • weight: 1 (0.9%)\n",
      "\n",
      "🔍 Missing patterns found: 2\n",
      "   Pattern 2: 1 rows missing ['weight']\n",
      "\n",
      "📋 Table: details_magic_items\n",
      "----------------------------------------\n",
      "✅ No missing values found\n",
      "\n",
      "📋 Table: details_weapons\n",
      "----------------------------------------\n",
      "✅ No missing values found\n",
      "\n",
      "📋 Table: details_armor\n",
      "----------------------------------------\n",
      "🕳️ Total missing values: 17\n",
      "📊 Columns with missing values: 3\n",
      "   • ac: 1 (7.7%)\n",
      "   • requirements: 10 (76.9%)\n",
      "   • stealth: 6 (46.2%)\n",
      "\n",
      "🔍 Missing patterns found: 4\n",
      "   Pattern 1: 5 rows missing ['requirements', 'stealth']\n",
      "   Pattern 2: 4 rows missing ['requirements']\n",
      "\n",
      "📋 Table: details_potions\n",
      "----------------------------------------\n",
      "✅ No missing values found\n",
      "\n",
      "📋 Table: details_poisons\n",
      "----------------------------------------\n",
      "🕳️ Total missing values: 1\n",
      "📊 Columns with missing values: 1\n",
      "   • dc: 1 (6.2%)\n",
      "\n",
      "🔍 Missing patterns found: 2\n",
      "   Pattern 2: 1 rows missing ['dc']\n",
      "\n",
      "📋 Table: all_products\n",
      "----------------------------------------\n",
      "✅ No missing values found\n",
      "\n",
      "📋 Table: customers\n",
      "----------------------------------------\n",
      "✅ No missing values found\n",
      "\n",
      "📋 Table: sales\n",
      "----------------------------------------\n",
      "🕳️ Total missing values: 455\n",
      "📊 Columns with missing values: 4\n",
      "   • sale_id: 72 (0.1%)\n",
      "   • customer_id: 61 (0.1%)\n",
      "   • product_id: 127 (0.2%)\n",
      "   • product_name: 195 (0.3%)\n",
      "\n",
      "🔍 Missing patterns found: 5\n",
      "   Pattern 2: 195 rows missing ['product_name']\n",
      "   Pattern 3: 127 rows missing ['product_id']\n",
      "\n",
      "============================================================\n",
      "✅ Missing value analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive missing value analysis\n",
    "print(\"🔍 MISSING VALUE PATTERN ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def analyze_missing_patterns(df, table_name):\n",
    "    \"\"\"Analyze missing value patterns in detail\"\"\"\n",
    "    print(f\"\\n📋 Table: {table_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    missing_counts = df.isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "    \n",
    "    if total_missing == 0:\n",
    "        print(\"✅ No missing values found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🕳️ Total missing values: {total_missing:,}\")\n",
    "    \n",
    "    # Missing values by column\n",
    "    cols_with_missing = missing_counts[missing_counts > 0]\n",
    "    print(f\"📊 Columns with missing values: {len(cols_with_missing)}\")\n",
    "    \n",
    "    for col, count in cols_with_missing.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"   • {col}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Missing value patterns\n",
    "    missing_patterns = df.isnull().groupby(list(df.columns)).size().sort_values(ascending=False)\n",
    "    \n",
    "    if len(missing_patterns) > 1:\n",
    "        print(f\"\\n🔍 Missing patterns found: {len(missing_patterns)}\")\n",
    "        for i, (pattern, count) in enumerate(missing_patterns.head(3).items()):\n",
    "            missing_cols = [col for col, is_missing in zip(df.columns, pattern) if is_missing]\n",
    "            if missing_cols:\n",
    "                print(f\"   Pattern {i+1}: {count:,} rows missing {missing_cols}\")\n",
    "    \n",
    "    return {\n",
    "        'total_missing': total_missing,\n",
    "        'columns_with_missing': cols_with_missing.to_dict(),\n",
    "        'missing_patterns': missing_patterns\n",
    "    }\n",
    "\n",
    "# Analyze all tables\n",
    "missing_analysis = {}\n",
    "for table_name, df in dataframes.items():\n",
    "    analysis = analyze_missing_patterns(df, table_name)\n",
    "    if analysis:\n",
    "        missing_analysis[table_name] = analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ Missing value analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b2379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 IMPLEMENTING MISSING VALUE HANDLING\n",
      "============================================================\n",
      "\n",
      "🔧 Processing: details_adventure_gear\n",
      "----------------------------------------\n",
      "\n",
      "🔍 Handling 'weight': 1 missing (0.9%)\n",
      "   📊 Imputed with mode: '1 lb.'\n",
      "   🏷️ Created indicator: weight_was_missing\n",
      "\n",
      "📊 Summary:\n",
      "   Original: (106, 6)\n",
      "   Final: (106, 7)\n",
      "   Rows removed: 0\n",
      "\n",
      "🔧 Processing: details_magic_items\n",
      "----------------------------------------\n",
      "✅ No missing values to handle\n",
      "\n",
      "🔧 Processing: details_weapons\n",
      "----------------------------------------\n",
      "✅ No missing values to handle\n",
      "\n",
      "🔧 Processing: details_armor\n",
      "----------------------------------------\n",
      "🗑️ Dropping 1 columns with >50% missing\n",
      "\n",
      "🔍 Handling 'ac': 1 missing (7.7%)\n",
      "   📊 Imputed with mode: '11 + Dex'\n",
      "   🏷️ Created indicator: ac_was_missing\n",
      "\n",
      "🔍 Handling 'stealth': 6 missing (46.2%)\n",
      "   📊 Imputed with mode: 'Disadvantage'\n",
      "   🏷️ Created indicator: stealth_was_missing\n",
      "\n",
      "📊 Summary:\n",
      "   Original: (13, 9)\n",
      "   Final: (13, 10)\n",
      "   Rows removed: 0\n",
      "\n",
      "🔧 Processing: details_potions\n",
      "----------------------------------------\n",
      "✅ No missing values to handle\n",
      "\n",
      "🔧 Processing: details_poisons\n",
      "----------------------------------------\n",
      "\n",
      "🔍 Handling 'dc': 1 missing (6.2%)\n",
      "   📊 Imputed with median: 13.00\n",
      "   🏷️ Created indicator: dc_was_missing\n",
      "\n",
      "📊 Summary:\n",
      "   Original: (16, 6)\n",
      "   Final: (16, 7)\n",
      "   Rows removed: 0\n",
      "\n",
      "🔧 Processing: all_products\n",
      "----------------------------------------\n",
      "✅ No missing values to handle\n",
      "\n",
      "🔧 Processing: customers\n",
      "----------------------------------------\n",
      "✅ No missing values to handle\n",
      "\n",
      "🔧 Processing: sales\n",
      "----------------------------------------\n",
      "\n",
      "🔍 Handling 'sale_id': 72 missing (0.1%)\n",
      "   📊 Imputed with mode: '210346-VVZNC'\n",
      "   🏷️ Created indicator: sale_id_was_missing\n",
      "\n",
      "🔍 Handling 'customer_id': 61 missing (0.1%)\n",
      "   📊 Imputed with mode: '416718-DW79WC'\n",
      "   🏷️ Created indicator: customer_id_was_missing\n",
      "\n",
      "🔍 Handling 'product_id': 127 missing (0.2%)\n",
      "   📊 Imputed with mode: '073-CNo'\n",
      "   🏷️ Created indicator: product_id_was_missing\n",
      "\n",
      "🔍 Handling 'product_name': 195 missing (0.3%)\n",
      "   📊 Imputed with mode: 'Flask or Tankard'\n",
      "   🏷️ Created indicator: product_name_was_missing\n",
      "\n",
      "📊 Summary:\n",
      "   Original: (57915, 7)\n",
      "   Final: (57915, 11)\n",
      "   Rows removed: 0\n",
      "\n",
      "============================================================\n",
      "✅ Missing value handling completed!\n"
     ]
    }
   ],
   "source": [
    "# Implement missing value handling strategies\n",
    "print(\"🔧 IMPLEMENTING MISSING VALUE HANDLING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def handle_missing_values(df, table_name):\n",
    "    \"\"\"Handle missing values with appropriate strategies\"\"\"\n",
    "    print(f\"\\n🔧 Processing: {table_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    handling_log = []\n",
    "    \n",
    "    # Check if there are missing values\n",
    "    if df_cleaned.isnull().sum().sum() == 0:\n",
    "        print(\"✅ No missing values to handle\")\n",
    "        return df_cleaned, []\n",
    "    \n",
    "    original_shape = df_cleaned.shape\n",
    "    \n",
    "    # 1. Drop columns with >50% missing values\n",
    "    missing_pct = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
    "    cols_to_drop = missing_pct[missing_pct > 50].index.tolist()\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        print(f\"🗑️ Dropping {len(cols_to_drop)} columns with >50% missing\")\n",
    "        df_cleaned = df_cleaned.drop(columns=cols_to_drop)\n",
    "        handling_log.append(f\"Dropped columns: {cols_to_drop}\")\n",
    "    \n",
    "    # 2. Drop rows with >80% missing values\n",
    "    missing_threshold = 0.8 * df_cleaned.shape[1]\n",
    "    rows_missing = df_cleaned.isnull().sum(axis=1)\n",
    "    rows_to_drop = rows_missing > missing_threshold\n",
    "    rows_dropped = rows_to_drop.sum()\n",
    "    \n",
    "    if rows_dropped > 0:\n",
    "        print(f\"🗑️ Dropping {rows_dropped} rows with excessive missing values\")\n",
    "        df_cleaned = df_cleaned[~rows_to_drop]\n",
    "        handling_log.append(f\"Dropped {rows_dropped} rows\")\n",
    "    \n",
    "    # 3. Handle remaining missing values by column type\n",
    "    remaining_missing = df_cleaned.isnull().sum()\n",
    "    cols_with_missing = remaining_missing[remaining_missing > 0].index.tolist()\n",
    "    \n",
    "    for col in cols_with_missing:\n",
    "        missing_count = df_cleaned[col].isnull().sum()\n",
    "        missing_pct = (missing_count / len(df_cleaned)) * 100\n",
    "        \n",
    "        print(f\"\\n🔍 Handling '{col}': {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "        \n",
    "        # Create indicator column\n",
    "        indicator_col = f\"{col}_was_missing\"\n",
    "        df_cleaned[indicator_col] = df_cleaned[col].isnull().astype(int)\n",
    "        \n",
    "        if df_cleaned[col].dtype in ['int64', 'float64', 'int32', 'float32']:\n",
    "            # Numerical column - use median\n",
    "            fill_value = df_cleaned[col].median()\n",
    "            df_cleaned[col] = df_cleaned[col].fillna(fill_value)\n",
    "            print(f\"   📊 Imputed with median: {fill_value:.2f}\")\n",
    "            handling_log.append(f\"Numeric imputation - {col}: median={fill_value:.2f}\")\n",
    "            \n",
    "        else:\n",
    "            # Categorical column - use mode\n",
    "            mode_values = df_cleaned[col].mode()\n",
    "            if len(mode_values) > 0:\n",
    "                fill_value = mode_values[0]\n",
    "                df_cleaned[col] = df_cleaned[col].fillna(fill_value)\n",
    "                print(f\"   📊 Imputed with mode: '{fill_value}'\")\n",
    "                handling_log.append(f\"Categorical imputation - {col}: mode='{fill_value}'\")\n",
    "            else:\n",
    "                df_cleaned[col] = df_cleaned[col].fillna('Unknown')\n",
    "                print(f\"   📊 Imputed with 'Unknown'\")\n",
    "                handling_log.append(f\"Categorical imputation - {col}: 'Unknown'\")\n",
    "        \n",
    "        print(f\"   🏷️ Created indicator: {indicator_col}\")\n",
    "    \n",
    "    final_shape = df_cleaned.shape\n",
    "    print(f\"\\n📊 Summary:\")\n",
    "    print(f\"   Original: {original_shape}\")\n",
    "    print(f\"   Final: {final_shape}\")\n",
    "    print(f\"   Rows removed: {original_shape[0] - final_shape[0]}\")\n",
    "    \n",
    "    return df_cleaned, handling_log\n",
    "\n",
    "# Apply missing value handling to all tables\n",
    "cleaned_dataframes = {}\n",
    "all_handling_logs = {}\n",
    "\n",
    "for table_name, df in dataframes.items():\n",
    "    cleaned_df, log = handle_missing_values(df, table_name)\n",
    "    cleaned_dataframes[table_name] = cleaned_df\n",
    "    all_handling_logs[table_name] = log\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ Missing value handling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16993a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MISSING VALUE HANDLING VALIDATION\n",
      "============================================================\n",
      "📊 VALIDATION SUMMARY:\n",
      "                 Table  Original_Rows  Final_Rows  Original_Cols  Final_Cols  Original_Missing  Final_Missing  Indicator_Cols\n",
      "details_adventure_gear            106         106              6           7                 1              0               1\n",
      "   details_magic_items            199         199              6           6                 0              0               0\n",
      "       details_weapons             37          37              8           8                 0              0               0\n",
      "         details_armor             13          13              9          10                17              0               2\n",
      "       details_potions             22          22              5           5                 0              0               0\n",
      "       details_poisons             16          16              6           7                 1              0               1\n",
      "          all_products            393         393              4           4                 0              0               0\n",
      "             customers           1423        1423              6           6                 0              0               0\n",
      "                 sales          57915       57915              7          11               455              0               4\n",
      "\n",
      "🎯 FINAL RESULTS:\n",
      "   ✅ All missing values handled successfully!\n",
      "   📊 Created 8 missing value indicators\n",
      "\n",
      "💾 Saved cleaned dataframes to data_intermediate/03_cleaned_dataframes.pkl\n",
      "✅ Saved handling logs to data_intermediate/03_handling_logs.pkl\n",
      "\n",
      "🎯 MISSING VALUES PHASE COMPLETE!\n",
      "   ➡️ Next: Run 04_duplicate_handling.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Validate and visualize results\n",
    "print(\"✅ MISSING VALUE HANDLING VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create before/after comparison\n",
    "validation_data = []\n",
    "\n",
    "for table_name in dataframes.keys():\n",
    "    original = dataframes[table_name]\n",
    "    cleaned = cleaned_dataframes[table_name]\n",
    "    \n",
    "    validation_data.append({\n",
    "        'Table': table_name,\n",
    "        'Original_Rows': original.shape[0],\n",
    "        'Final_Rows': cleaned.shape[0],\n",
    "        'Original_Cols': original.shape[1],\n",
    "        'Final_Cols': cleaned.shape[1],\n",
    "        'Original_Missing': original.isnull().sum().sum(),\n",
    "        'Final_Missing': cleaned.isnull().sum().sum(),\n",
    "        'Indicator_Cols': len([col for col in cleaned.columns if '_was_missing' in col])\n",
    "    })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_data)\n",
    "print(\"📊 VALIDATION SUMMARY:\")\n",
    "print(validation_df.to_string(index=False))\n",
    "\n",
    "# Final check\n",
    "total_remaining_missing = sum(df.isnull().sum().sum() for df in cleaned_dataframes.values())\n",
    "total_indicators = sum(len([col for col in df.columns if '_was_missing' in col]) for df in cleaned_dataframes.values())\n",
    "\n",
    "print(f\"\\n🎯 FINAL RESULTS:\")\n",
    "if total_remaining_missing == 0:\n",
    "    print(f\"   ✅ All missing values handled successfully!\")\n",
    "else:\n",
    "    print(f\"   ⚠️ {total_remaining_missing} missing values remain\")\n",
    "\n",
    "print(f\"   📊 Created {total_indicators} missing value indicators\")\n",
    "\n",
    "# Save results\n",
    "with open('data_intermediate/03_cleaned_dataframes.pkl', 'wb') as f:\n",
    "    pickle.dump(cleaned_dataframes, f)\n",
    "print(f\"\\n💾 Saved cleaned dataframes to data_intermediate/03_cleaned_dataframes.pkl\")\n",
    "\n",
    "with open('data_intermediate/03_handling_logs.pkl', 'wb') as f:\n",
    "    pickle.dump(all_handling_logs, f)\n",
    "print(f\"✅ Saved handling logs to data_intermediate/03_handling_logs.pkl\")\n",
    "\n",
    "print(f\"\\n🎯 MISSING VALUES PHASE COMPLETE!\")\n",
    "print(f\"   ➡️ Next: Run 04_duplicate_handling.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5baec0",
   "metadata": {},
   "source": [
    "## 🎉 Phase 3 Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "- ✅ Analyzed missing value patterns across all tables\n",
    "- ✅ Implemented appropriate handling strategies\n",
    "- ✅ Created missing value indicator variables\n",
    "- ✅ Validated handling effectiveness\n",
    "- ✅ Preserved data integrity throughout process\n",
    "\n",
    "**Handling Strategies Applied:**\n",
    "- Dropped columns with >50% missing values\n",
    "- Removed rows with excessive missing data\n",
    "- Imputed numerical values with median\n",
    "- Imputed categorical values with mode\n",
    "- Created indicator variables for missingness patterns\n",
    "\n",
    "**Next Steps:**\n",
    "- Run `04_duplicate_handling.ipynb` to remove duplicate records\n",
    "\n",
    "**Data Files Created:**\n",
    "- `data_intermediate/03_cleaned_dataframes.pkl` - DataFrames with handled missing values\n",
    "- `data_intermediate/03_handling_logs.pkl` - Detailed handling operation logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
