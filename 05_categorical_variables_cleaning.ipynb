{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd498df",
   "metadata": {},
   "source": [
    "# ğŸ› ï¸ Adventurer Mart: ML Data Preparation - Part 5\n",
    "\n",
    "## ğŸ§¹ 5. Categorical Variables Cleaning\n",
    "\n",
    "This notebook systematically cleans and encodes categorical variables for ML compatibility.\n",
    "\n",
    "### ğŸ¯ Objectives\n",
    "- Normalize text and categorical values\n",
    "- Consolidate similar categories\n",
    "- Apply appropriate encoding techniques\n",
    "- Create ML-ready categorical features\n",
    "- Export encoded data for next phase\n",
    "\n",
    "### ğŸ”§ Processing Strategy\n",
    "- **Text Normalization**: Standardize case, spacing, and punctuation\n",
    "- **Category Consolidation**: Merge similar values and handle rare categories\n",
    "- **Smart Encoding**: Choose optimal encoding based on cardinality\n",
    "- **Feature Engineering**: Create meaningful categorical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e7595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Libraries imported successfully!\n",
      "ğŸ§¹ Categorical cleaning tools ready\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ“¦ Libraries imported successfully!\")\n",
    "print(\"ğŸ§¹ Categorical cleaning tools ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4c75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ LOADING DATA FROM PHASE 4\n",
      "==================================================\n",
      "âœ… Loaded deduplicated dataframes from Phase 4\n",
      "\n",
      "ğŸ“Š Dataset Status:\n",
      "   â€¢ Tables: 9\n",
      "   â€¢ Total records: 56,335\n",
      "   â€¢ Categorical columns: 53\n"
     ]
    }
   ],
   "source": [
    "# Load data from previous phase\n",
    "print(\"ğŸ“‚ LOADING DATA FROM PHASE 4\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load deduplicated dataframes\n",
    "    with open('data_intermediate/04_deduplicated_dataframes.pkl', 'rb') as f:\n",
    "        dataframes = pickle.load(f)\n",
    "    print(\"âœ… Loaded deduplicated dataframes from Phase 4\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Dataset Status:\")\n",
    "    print(f\"   â€¢ Tables: {len(dataframes)}\")\n",
    "    total_records = sum(len(df) for df in dataframes.values())\n",
    "    print(f\"   â€¢ Total records: {total_records:,}\")\n",
    "    \n",
    "    # Count categorical columns\n",
    "    total_categorical = sum(len(df.select_dtypes(include=['object']).columns) for df in dataframes.values())\n",
    "    print(f\"   â€¢ Categorical columns: {total_categorical}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Error loading data: {e}\")\n",
    "    print(\"ğŸ”„ Please run previous phases first\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3be758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” CATEGORICAL VARIABLES ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Table: details_adventure_gear\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 6\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 106\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '01-Ars': 1 (0.9%)\n",
      "      2. '83-Rrs': 1 (0.9%)\n",
      "      3. '81-Rrs': 1 (0.9%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 105\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Flask or Tankard': 2 (1.9%)\n",
      "      2. 'Abacus': 1 (0.9%)\n",
      "      3. 'Parchment (one sheet)': 1 (0.9%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 25\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '1 gp': 19 (17.9%)\n",
      "      2. '2 gp': 15 (14.2%)\n",
      "      3. '5 gp': 14 (13.2%)\n",
      "\n",
      "ğŸ” Analyzing: weight\n",
      "   ğŸ“Š Unique values: 19\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '1 lb.': 26 (24.5%)\n",
      "      2. '2 lb.': 16 (15.1%)\n",
      "      3. '-': 16 (15.1%)\n",
      "\n",
      "ğŸ” Analyzing: category\n",
      "   ğŸ“Š Unique values: 6\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Others': 80 (75.5%)\n",
      "      2. 'Musical instrument': 10 (9.4%)\n",
      "      3. 'Arcane Focus': 5 (4.7%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 106\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'adventure_gear': 106 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: details_magic_items\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 6\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 199\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '001-ACo': 1 (0.5%)\n",
      "      2. '184-ICo': 1 (0.5%)\n",
      "      3. '193-ICo': 1 (0.5%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 199\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Ammunition +1 (Per)': 1 (0.5%)\n",
      "      2. 'Ioun Stone Protection': 1 (0.5%)\n",
      "      3. 'Ioun Stone Awareness': 1 (0.5%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 49\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '2,000 gp': 20 (10.1%)\n",
      "      2. '1,000 gp': 19 (9.5%)\n",
      "      3. '500 gp': 18 (9.0%)\n",
      "\n",
      "ğŸ” Analyzing: rarity\n",
      "   ğŸ“Š Unique values: 3\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Rare': 114 (57.3%)\n",
      "      2. 'Uncommon': 83 (41.7%)\n",
      "      3. 'Common': 2 (1.0%)\n",
      "\n",
      "ğŸ” Analyzing: category\n",
      "   ğŸ“Š Unique values: 4\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Combat Items': 93 (46.7%)\n",
      "      2. 'Non Combat Items': 57 (28.6%)\n",
      "      3. 'Consumable Items': 32 (16.1%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 199\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'magic_item': 199 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: details_weapons\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 8\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 37\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '01-Cns': 1 (2.7%)\n",
      "      2. '20-Hns': 1 (2.7%)\n",
      "      3. '22-Lns': 1 (2.7%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 37\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Club': 1 (2.7%)\n",
      "      2. 'Halberd': 1 (2.7%)\n",
      "      3. 'Longsword': 1 (2.7%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 14\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '10 gp': 6 (16.2%)\n",
      "      2. '5 gp': 5 (13.5%)\n",
      "      3. '25 gp': 4 (10.8%)\n",
      "\n",
      "ğŸ” Analyzing: damage\n",
      "   ğŸ“Š Unique values: 17\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '1d6 Piercing': 6 (16.2%)\n",
      "      2. '1d8 Piercing': 4 (10.8%)\n",
      "      3. '1d4 Bludgeon': 3 (8.1%)\n",
      "\n",
      "ğŸ” Analyzing: weight\n",
      "   ğŸ“Š Unique values: 11\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '2 lb.': 12 (32.4%)\n",
      "      2. '3 lb.': 6 (16.2%)\n",
      "      3. '5 lb.': 4 (10.8%)\n",
      "\n",
      "ğŸ” Analyzing: properties\n",
      "   ğŸ“Š Unique values: 24\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '-': 4 (10.8%)\n",
      "      2. 'Versatile (1d10)': 3 (8.1%)\n",
      "      3. 'Heavy, Two-handed': 3 (8.1%)\n",
      "\n",
      "ğŸ” Analyzing: category\n",
      "   ğŸ“Š Unique values: 4\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Martial Melee Weapons': 18 (48.6%)\n",
      "      2. 'Simple Melee Weapons': 10 (27.0%)\n",
      "      3. 'Martial Ranged Weapons': 5 (13.5%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 37\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'weapon': 37 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: details_armor\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 8\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 13\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '01-Por': 1 (7.7%)\n",
      "      2. '02-Lor': 1 (7.7%)\n",
      "      3. '03-Sor': 1 (7.7%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 13\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Padded': 1 (7.7%)\n",
      "      2. 'Leather': 1 (7.7%)\n",
      "      3. 'Studded Leather': 1 (7.7%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 10\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '10 gp': 3 (23.1%)\n",
      "      2. '50 gp': 2 (15.4%)\n",
      "      3. '5 gp': 1 (7.7%)\n",
      "\n",
      "ğŸ” Analyzing: ac\n",
      "   ğŸ“Š Unique values: 10\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '11 + Dex': 3 (23.1%)\n",
      "      2. '14 + Dex(max2)': 2 (15.4%)\n",
      "      3. '12 + Dex': 1 (7.7%)\n",
      "\n",
      "ğŸ” Analyzing: weight\n",
      "   ğŸ“Š Unique values: 11\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '20 lb.': 2 (15.4%)\n",
      "      2. '40 lb.': 2 (15.4%)\n",
      "      3. '8 lb.': 1 (7.7%)\n",
      "\n",
      "ğŸ” Analyzing: stealth\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Disadvantage': 13 (100.0%)\n",
      "\n",
      "ğŸ” Analyzing: category\n",
      "   ğŸ“Š Unique values: 3\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Medium Armor': 5 (38.5%)\n",
      "      2. 'Heavy Armor': 5 (38.5%)\n",
      "      3. 'Light Armor': 3 (23.1%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 13\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'armor': 13 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: details_potions\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 5\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 22\n",
      "   ğŸ“Š Non-null count: 22\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '01-Pon': 1 (4.5%)\n",
      "      2. '02-Pon': 1 (4.5%)\n",
      "      3. '29-Pre': 1 (4.5%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 22\n",
      "   ğŸ“Š Non-null count: 22\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Potion of Healing': 1 (4.5%)\n",
      "      2. 'Potion of Greater Healing': 1 (4.5%)\n",
      "      3. 'Potion of Frost Giant Strength': 1 (4.5%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 16\n",
      "   ğŸ“Š Non-null count: 22\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '180 gp': 4 (18.2%)\n",
      "      2. '150 gp': 2 (9.1%)\n",
      "      3. '270 gp': 2 (9.1%)\n",
      "\n",
      "ğŸ” Analyzing: rarity\n",
      "   ğŸ“Š Unique values: 3\n",
      "   ğŸ“Š Non-null count: 22\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Uncommon': 10 (45.5%)\n",
      "      2. 'Rare': 10 (45.5%)\n",
      "      3. 'Common': 2 (9.1%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 22\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'potion': 22 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: details_poisons\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 5\n",
      "\n",
      "ğŸ” Analyzing: item_id\n",
      "   ğŸ“Š Unique values: 16\n",
      "   ğŸ“Š Non-null count: 16\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '01-Aed': 1 (6.2%)\n",
      "      2. '02-Ted': 1 (6.2%)\n",
      "      3. '03-Cct': 1 (6.2%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 16\n",
      "   ğŸ“Š Non-null count: 16\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Assassin's blood': 1 (6.2%)\n",
      "      2. 'Truth serum': 1 (6.2%)\n",
      "      3. 'Carrion crawler mucus': 1 (6.2%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 12\n",
      "   ğŸ“Š Non-null count: 16\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '200 gp': 3 (18.8%)\n",
      "      2. '150 gp': 2 (12.5%)\n",
      "      3. '250 gp': 2 (12.5%)\n",
      "\n",
      "ğŸ” Analyzing: category\n",
      "   ğŸ“Š Unique values: 4\n",
      "   ğŸ“Š Non-null count: 16\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Ingested': 6 (37.5%)\n",
      "      2. 'Injury': 4 (25.0%)\n",
      "      3. 'Contact': 3 (18.8%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 1\n",
      "   ğŸ“Š Non-null count: 16\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'poison': 16 (100.0%)\n",
      "\n",
      "ğŸ“‹ Table: all_products\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 4\n",
      "\n",
      "ğŸ” Analyzing: product_id\n",
      "   ğŸ“Š Unique values: 393\n",
      "   ğŸ“Š Non-null count: 393\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '001-ACo': 1 (0.3%)\n",
      "      2. '74-Prs': 1 (0.3%)\n",
      "      3. '71-Prs': 1 (0.3%)\n",
      "\n",
      "ğŸ” Analyzing: product_name\n",
      "   ğŸ“Š Unique values: 392\n",
      "   ğŸ“Š Non-null count: 393\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Flask or Tankard': 2 (0.5%)\n",
      "      2. 'Ammunition +1 (Per)': 1 (0.3%)\n",
      "      3. 'Lock': 1 (0.3%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 74\n",
      "   ğŸ“Š Non-null count: 393\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '1 gp': 22 (5.6%)\n",
      "      2. '2,000 gp': 21 (5.3%)\n",
      "      3. '5 gp': 21 (5.3%)\n",
      "\n",
      "ğŸ” Analyzing: type\n",
      "   ğŸ“Š Unique values: 6\n",
      "   ğŸ“Š Non-null count: 393\n",
      "   ğŸ“ˆ Category type: Low Cardinality\n",
      "   ğŸ¯ Recommended encoding: One-Hot Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'magic_item': 199 (50.6%)\n",
      "      2. 'adventure_gear': 106 (27.0%)\n",
      "      3. 'weapon': 37 (9.4%)\n",
      "\n",
      "ğŸ“‹ Table: customers\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 5\n",
      "\n",
      "ğŸ” Analyzing: customer_id\n",
      "   ğŸ“Š Unique values: 1,423\n",
      "   ğŸ“Š Non-null count: 1,423\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '415996-753LC5': 1 (0.1%)\n",
      "      2. '416974-L5EFJP': 1 (0.1%)\n",
      "      3. '416950-7ZK94Y': 1 (0.1%)\n",
      "\n",
      "ğŸ” Analyzing: name\n",
      "   ğŸ“Š Unique values: 1,423\n",
      "   ğŸ“Š Non-null count: 1,423\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Veklani  Daargen': 1 (0.1%)\n",
      "      2. 'Tegan  Van Devries': 1 (0.1%)\n",
      "      3. 'Gryphero  Brightwater': 1 (0.1%)\n",
      "\n",
      "ğŸ” Analyzing: sex\n",
      "   ğŸ“Š Unique values: 2\n",
      "   ğŸ“Š Non-null count: 1,423\n",
      "   ğŸ“ˆ Category type: Binary\n",
      "   ğŸ¯ Recommended encoding: Label Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'female': 768 (54.0%)\n",
      "      2. 'male': 655 (46.0%)\n",
      "\n",
      "ğŸ” Analyzing: race\n",
      "   ğŸ“Š Unique values: 11\n",
      "   ğŸ“Š Non-null count: 1,423\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Drow': 156 (11.0%)\n",
      "      2. 'Dwarf': 144 (10.1%)\n",
      "      3. 'Half-Elf': 141 (9.9%)\n",
      "\n",
      "ğŸ” Analyzing: class\n",
      "   ğŸ“Š Unique values: 12\n",
      "   ğŸ“Š Non-null count: 1,423\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Monk': 134 (9.4%)\n",
      "      2. 'Cleric': 127 (8.9%)\n",
      "      3. 'Ranger': 126 (8.9%)\n",
      "\n",
      "ğŸ“‹ Table: sales\n",
      "----------------------------------------\n",
      "ğŸ“ Categorical columns: 6\n",
      "\n",
      "ğŸ” Analyzing: sale_id\n",
      "   ğŸ“Š Unique values: 54,068\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: High Cardinality\n",
      "   ğŸ¯ Recommended encoding: Label + Frequency\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '210346-VVZNC': 59 (0.1%)\n",
      "      2. '436100-4WBAB': 1 (0.0%)\n",
      "      3. '691566-GBDUV': 1 (0.0%)\n",
      "\n",
      "ğŸ” Analyzing: date\n",
      "   ğŸ“Š Unique values: 2,556\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '2019-12-15 00:00:00': 40 (0.1%)\n",
      "      2. '2019-08-25 00:00:00': 39 (0.1%)\n",
      "      3. '2023-07-09 00:00:00': 37 (0.1%)\n",
      "\n",
      "ğŸ” Analyzing: customer_id\n",
      "   ğŸ“Š Unique values: 1,423\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '416718-DW79WC': 113 (0.2%)\n",
      "      2. '416236-13C9XQ': 59 (0.1%)\n",
      "      3. '416292-CQZCUC': 59 (0.1%)\n",
      "\n",
      "ğŸ” Analyzing: product_id\n",
      "   ğŸ“Š Unique values: 393\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '073-CNo': 286 (0.5%)\n",
      "      2. '226-ACo': 175 (0.3%)\n",
      "      3. '254-SCo': 170 (0.3%)\n",
      "\n",
      "ğŸ” Analyzing: price\n",
      "   ğŸ“Š Unique values: 74\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. '1 gp': 2,984 (5.5%)\n",
      "      2. '2,000 gp': 2,936 (5.4%)\n",
      "      3. '5 gp': 2,893 (5.3%)\n",
      "\n",
      "ğŸ” Analyzing: product_name\n",
      "   ğŸ“Š Unique values: 393\n",
      "   ğŸ“Š Non-null count: 54,126\n",
      "   ğŸ“ˆ Category type: Medium Cardinality\n",
      "   ğŸ¯ Recommended encoding: Frequency Encoding\n",
      "   ğŸ” Top 3 values:\n",
      "      1. 'Flask or Tankard': 448 (0.8%)\n",
      "      2. 'Adamantine Armor': 175 (0.3%)\n",
      "      3. 'Saddle of the Cavalier': 170 (0.3%)\n",
      "\n",
      "============================================================\n",
      "âœ… Categorical analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Analyze categorical variables in detail\n",
    "print(\"ğŸ” CATEGORICAL VARIABLES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def analyze_categorical_variables(df, table_name):\n",
    "    \"\"\"Analyze categorical variables for cleaning strategy\"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if not categorical_cols:\n",
    "        print(f\"\\nğŸ“‹ {table_name}: No categorical columns found\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Table: {table_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ğŸ“ Categorical columns: {len(categorical_cols)}\")\n",
    "    \n",
    "    analysis = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\nğŸ” Analyzing: {col}\")\n",
    "        \n",
    "        unique_count = df[col].nunique()\n",
    "        total_count = len(df[col].dropna())\n",
    "        value_counts = df[col].value_counts()\n",
    "        \n",
    "        print(f\"   ğŸ“Š Unique values: {unique_count:,}\")\n",
    "        print(f\"   ğŸ“Š Non-null count: {total_count:,}\")\n",
    "        \n",
    "        # Check for text normalization issues\n",
    "        sample_values = df[col].dropna().astype(str).unique()[:10]\n",
    "        \n",
    "        # Case inconsistencies\n",
    "        case_variants = {}\n",
    "        for value in sample_values:\n",
    "            normalized = value.lower().strip()\n",
    "            if normalized not in case_variants:\n",
    "                case_variants[normalized] = []\n",
    "            case_variants[normalized].append(value)\n",
    "        \n",
    "        case_issues = {k: v for k, v in case_variants.items() if len(v) > 1}\n",
    "        if case_issues:\n",
    "            print(f\"   âš ï¸ Case inconsistencies found: {len(case_issues)} groups\")\n",
    "        \n",
    "        # Cardinality analysis\n",
    "        cardinality_ratio = unique_count / total_count if total_count > 0 else 0\n",
    "        \n",
    "        if cardinality_ratio > 0.8:\n",
    "            category_type = \"High Cardinality\"\n",
    "            encoding_strategy = \"Label + Frequency\"\n",
    "        elif unique_count <= 2:\n",
    "            category_type = \"Binary\"\n",
    "            encoding_strategy = \"Label Encoding\"\n",
    "        elif unique_count <= 10:\n",
    "            category_type = \"Low Cardinality\"\n",
    "            encoding_strategy = \"One-Hot Encoding\"\n",
    "        else:\n",
    "            category_type = \"Medium Cardinality\"\n",
    "            encoding_strategy = \"Frequency Encoding\"\n",
    "        \n",
    "        print(f\"   ğŸ“ˆ Category type: {category_type}\")\n",
    "        print(f\"   ğŸ¯ Recommended encoding: {encoding_strategy}\")\n",
    "        \n",
    "        # Top values\n",
    "        print(f\"   ğŸ” Top 3 values:\")\n",
    "        for i, (value, count) in enumerate(value_counts.head(3).items()):\n",
    "            pct = (count / total_count) * 100\n",
    "            print(f\"      {i+1}. '{value}': {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        analysis[col] = {\n",
    "            'unique_count': unique_count,\n",
    "            'total_count': total_count,\n",
    "            'cardinality_ratio': cardinality_ratio,\n",
    "            'category_type': category_type,\n",
    "            'encoding_strategy': encoding_strategy,\n",
    "            'case_issues': case_issues,\n",
    "            'top_values': value_counts.head(5).to_dict()\n",
    "        }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze all tables\n",
    "categorical_analysis = {}\n",
    "for table_name, df in dataframes.items():\n",
    "    analysis = analyze_categorical_variables(df, table_name)\n",
    "    if analysis:\n",
    "        categorical_analysis[table_name] = analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Categorical analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34530f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ CATEGORICAL TEXT NORMALIZATION\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ Processing: details_adventure_gear\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 106 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 106 â†’ 1 (-105)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 104 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 105 â†’ 2 (-103)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 11 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 25 â†’ 14 (-11)\n",
      "\n",
      "ğŸ” Normalizing: weight\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 7 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 19 â†’ 13 (-6)\n",
      "\n",
      "ğŸ” Normalizing: category\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 6 â†’ 6 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: details_magic_items\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 199 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 199 â†’ 1 (-198)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 199 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 199 â†’ 1 (-198)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 24 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 49 â†’ 26 (-23)\n",
      "\n",
      "ğŸ” Normalizing: rarity\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 3 â†’ 3 (-0)\n",
      "\n",
      "ğŸ” Normalizing: category\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 4 â†’ 4 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: details_weapons\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 37 â†’ 37 (-0)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 37 â†’ 37 (-0)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 14 â†’ 14 (-0)\n",
      "\n",
      "ğŸ” Normalizing: damage\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 17 â†’ 17 (-0)\n",
      "\n",
      "ğŸ” Normalizing: weight\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 11 â†’ 11 (-0)\n",
      "\n",
      "ğŸ” Normalizing: properties\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 24 â†’ 24 (-0)\n",
      "\n",
      "ğŸ” Normalizing: category\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 4 â†’ 4 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: details_armor\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 13 â†’ 13 (-0)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 13 â†’ 13 (-0)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 10 â†’ 10 (-0)\n",
      "\n",
      "ğŸ” Normalizing: ac\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 10 â†’ 10 (-0)\n",
      "\n",
      "ğŸ” Normalizing: weight\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 11 â†’ 11 (-0)\n",
      "\n",
      "ğŸ” Normalizing: stealth\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ” Normalizing: category\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 3 â†’ 3 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: details_potions\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 22 â†’ 22 (-0)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 22 â†’ 22 (-0)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 16 â†’ 16 (-0)\n",
      "\n",
      "ğŸ” Normalizing: rarity\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 3 â†’ 3 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: details_poisons\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: item_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 16 â†’ 16 (-0)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 16 â†’ 16 (-0)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 12 â†’ 12 (-0)\n",
      "\n",
      "ğŸ” Normalizing: category\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 4 â†’ 4 (-0)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 1 â†’ 1 (-0)\n",
      "\n",
      "ğŸ”§ Processing: all_products\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: product_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 393 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 393 â†’ 1 (-392)\n",
      "\n",
      "ğŸ” Normalizing: product_name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 392 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 392 â†’ 1 (-391)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 37 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 74 â†’ 38 (-36)\n",
      "\n",
      "ğŸ” Normalizing: type\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 6 â†’ 6 (-0)\n",
      "\n",
      "ğŸ”§ Processing: customers\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: customer_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 1423 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 1423 â†’ 1 (-1422)\n",
      "\n",
      "ğŸ” Normalizing: name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 1423 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 1423 â†’ 1 (-1422)\n",
      "\n",
      "ğŸ” Normalizing: sex\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 2 â†’ 2 (-0)\n",
      "\n",
      "ğŸ” Normalizing: race\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ”„ Consolidated 'half-elf' â†’ 'half_elf'\n",
      "   ğŸ”„ Consolidated 'half-orc' â†’ 'half_orc'\n",
      "   ğŸ”„ Consolidated 'dragonborn' â†’ 'dragonborn'\n",
      "   ğŸ“Š Categories: 11 â†’ 11 (-0)\n",
      "\n",
      "ğŸ” Normalizing: class\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“Š Categories: 12 â†’ 12 (-0)\n",
      "\n",
      "ğŸ”§ Processing: sales\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Normalizing: sale_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 54068 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 54068 â†’ 1 (-54067)\n",
      "\n",
      "ğŸ” Normalizing: date\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 2556 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 2556 â†’ 1 (-2555)\n",
      "\n",
      "ğŸ” Normalizing: customer_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 1423 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 1423 â†’ 1 (-1422)\n",
      "\n",
      "ğŸ” Normalizing: product_id\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 393 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 393 â†’ 1 (-392)\n",
      "\n",
      "ğŸ” Normalizing: price\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 38 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 74 â†’ 37 (-37)\n",
      "\n",
      "ğŸ” Normalizing: product_name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 392 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 393 â†’ 1 (-392)\n",
      "\n",
      "============================================================\n",
      "âœ… Text normalization completed!\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 38 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 74 â†’ 37 (-37)\n",
      "\n",
      "ğŸ” Normalizing: product_name\n",
      "   âœ… Applied basic text normalization\n",
      "   ğŸ“‰ Consolidated 392 rare categories â†’ 'other'\n",
      "   ğŸ“Š Categories: 393 â†’ 1 (-392)\n",
      "\n",
      "============================================================\n",
      "âœ… Text normalization completed!\n"
     ]
    }
   ],
   "source": [
    "# Clean and normalize categorical text\n",
    "print(\"ğŸ§¹ CATEGORICAL TEXT NORMALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def normalize_categorical_text(df, table_name, analysis):\n",
    "    \"\"\"Normalize and clean categorical text\"\"\"\n",
    "    print(f\"\\nğŸ”§ Processing: {table_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if not analysis:\n",
    "        print(\"âœ… No categorical columns to normalize\")\n",
    "        return df.copy(), []\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    normalization_log = []\n",
    "    \n",
    "    for col, col_analysis in analysis.items():\n",
    "        print(f\"\\nğŸ” Normalizing: {col}\")\n",
    "        \n",
    "        original_unique = col_analysis['unique_count']\n",
    "        \n",
    "        # Basic text normalization\n",
    "        df_normalized[col] = df_normalized[col].astype(str)\n",
    "        df_normalized[col] = df_normalized[col].str.strip().str.lower()\n",
    "        df_normalized[col] = df_normalized[col].str.replace(r'\\s+', ' ', regex=True)\n",
    "        df_normalized[col] = df_normalized[col].replace('nan', np.nan)\n",
    "        \n",
    "        print(f\"   âœ… Applied basic text normalization\")\n",
    "        \n",
    "        # Domain-specific consolidations\n",
    "        if 'race' in col.lower():\n",
    "            consolidations = {\n",
    "                'half-elf': 'half_elf', 'half elf': 'half_elf',\n",
    "                'half-orc': 'half_orc', 'half orc': 'half_orc',\n",
    "                'dragonborn': 'dragonborn', 'dragon born': 'dragonborn'\n",
    "            }\n",
    "            for old, new in consolidations.items():\n",
    "                mask = df_normalized[col] == old\n",
    "                if mask.any():\n",
    "                    df_normalized.loc[mask, col] = new\n",
    "                    print(f\"   ğŸ”„ Consolidated '{old}' â†’ '{new}'\")\n",
    "        \n",
    "        # Handle rare categories (combine if >10 unique and <1% frequency)\n",
    "        if original_unique > 10:\n",
    "            value_counts = df_normalized[col].value_counts()\n",
    "            total = len(df_normalized[col].dropna())\n",
    "            rare_threshold = max(1, total * 0.01)\n",
    "            \n",
    "            rare_categories = value_counts[value_counts < rare_threshold]\n",
    "            if len(rare_categories) > 0:\n",
    "                rare_list = rare_categories.index.tolist()\n",
    "                df_normalized.loc[df_normalized[col].isin(rare_list), col] = 'other'\n",
    "                print(f\"   ğŸ“‰ Consolidated {len(rare_categories)} rare categories â†’ 'other'\")\n",
    "                normalization_log.append(f\"{col}: Consolidated {len(rare_categories)} rare categories\")\n",
    "        \n",
    "        final_unique = df_normalized[col].nunique()\n",
    "        reduction = original_unique - final_unique\n",
    "        print(f\"   ğŸ“Š Categories: {original_unique} â†’ {final_unique} (-{reduction})\")\n",
    "        \n",
    "        normalization_log.append(f\"{col}: Basic normalization applied\")\n",
    "    \n",
    "    return df_normalized, normalization_log\n",
    "\n",
    "# Apply normalization to all tables\n",
    "normalized_dataframes = {}\n",
    "all_normalization_logs = {}\n",
    "\n",
    "for table_name, df in dataframes.items():\n",
    "    analysis = categorical_analysis.get(table_name, {})\n",
    "    normalized_df, log = normalize_categorical_text(df, table_name, analysis)\n",
    "    normalized_dataframes[table_name] = normalized_df\n",
    "    all_normalization_logs[table_name] = log\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Text normalization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16ecc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ CATEGORICAL VARIABLE ENCODING\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_adventure_gear\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 2\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 14\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: weight\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 13\n",
      "   âœ… Created: weight_freq, weight_label\n",
      "\n",
      "ğŸ” Encoding: category\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 6\n",
      "   âœ… Created: 6 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_magic_items\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 26\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: rarity\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 3\n",
      "   âœ… Created: 3 dummy variables\n",
      "\n",
      "ğŸ” Encoding: category\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 4\n",
      "   âœ… Created: 4 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_weapons\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 37\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 37\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 14\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: damage\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 17\n",
      "   âœ… Created: damage_freq, damage_label\n",
      "\n",
      "ğŸ” Encoding: weight\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 11\n",
      "   âœ… Created: weight_freq, weight_label\n",
      "\n",
      "ğŸ” Encoding: properties\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 24\n",
      "   âœ… Created: properties_freq, properties_label\n",
      "\n",
      "ğŸ” Encoding: category\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 4\n",
      "   âœ… Created: 4 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_armor\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 13\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 13\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 10\n",
      "   âœ… Created: 10 dummy variables\n",
      "\n",
      "ğŸ” Encoding: ac\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 10\n",
      "   âœ… Created: 10 dummy variables\n",
      "\n",
      "ğŸ” Encoding: weight\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 11\n",
      "   âœ… Created: weight_freq, weight_freq_norm, weight_label\n",
      "\n",
      "ğŸ” Encoding: stealth\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: stealth_label\n",
      "\n",
      "ğŸ” Encoding: category\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 3\n",
      "   âœ… Created: 3 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_potions\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 22\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 22\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 16\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: rarity\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 3\n",
      "   âœ… Created: 3 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: details_poisons\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: item_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 16\n",
      "   âœ… Created: item_id_freq, item_id_freq_norm, item_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 16\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 12\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: category\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 4\n",
      "   âœ… Created: 4 dummy variables\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: type_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: all_products\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: product_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: product_id_freq, product_id_freq_norm, product_id_label\n",
      "\n",
      "ğŸ” Encoding: product_name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: product_name_freq, product_name_freq_norm, product_name_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 38\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: type\n",
      "   ğŸ“Š Strategy: One-Hot Encoding\n",
      "   ğŸ“Š Unique values: 6\n",
      "   âœ… Created: 6 dummy variables\n",
      "\n",
      "ğŸ”§ Encoding variables for: customers\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: customer_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: customer_id_freq, customer_id_freq_norm, customer_id_label\n",
      "\n",
      "ğŸ” Encoding: name\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: name_freq, name_freq_norm, name_label\n",
      "\n",
      "ğŸ” Encoding: sex\n",
      "   ğŸ“Š Strategy: Label Encoding\n",
      "   ğŸ“Š Unique values: 2\n",
      "   âœ… Created: sex_label\n",
      "\n",
      "ğŸ” Encoding: race\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 11\n",
      "   âœ… Created: race_freq, race_label\n",
      "\n",
      "ğŸ” Encoding: class\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 12\n",
      "   âœ… Created: class_freq, class_label\n",
      "\n",
      "ğŸ”§ Encoding variables for: sales\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ” Encoding: sale_id\n",
      "   ğŸ“Š Strategy: Label + Frequency\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: sale_id_freq, sale_id_freq_norm, sale_id_label\n",
      "\n",
      "ğŸ” Encoding: date\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: date_freq, date_label\n",
      "\n",
      "ğŸ” Encoding: customer_id\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: customer_id_freq, customer_id_label\n",
      "\n",
      "ğŸ” Encoding: product_id\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: product_id_freq, product_id_label\n",
      "\n",
      "ğŸ” Encoding: price\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 37\n",
      "   âœ… Created: price_freq, price_label\n",
      "\n",
      "ğŸ” Encoding: product_name\n",
      "   ğŸ“Š Strategy: Frequency Encoding\n",
      "   ğŸ“Š Unique values: 1\n",
      "   âœ… Created: product_name_freq, product_name_label\n",
      "\n",
      "============================================================\n",
      "âœ… Categorical encoding completed!\n"
     ]
    }
   ],
   "source": [
    "# Apply categorical encoding strategies\n",
    "print(\"ğŸ¯ CATEGORICAL VARIABLE ENCODING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def encode_categorical_variables(df, table_name, analysis):\n",
    "    \"\"\"Apply optimal encoding strategies to categorical variables\"\"\"\n",
    "    print(f\"\\nğŸ”§ Encoding variables for: {table_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if not analysis:\n",
    "        print(\"âœ… No categorical variables to encode\")\n",
    "        return df.copy(), {}\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    encoding_info = {}\n",
    "    \n",
    "    for col, col_analysis in analysis.items():\n",
    "        if col not in df_encoded.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nğŸ” Encoding: {col}\")\n",
    "        strategy = col_analysis['encoding_strategy']\n",
    "        unique_count = df_encoded[col].nunique()\n",
    "        \n",
    "        print(f\"   ğŸ“Š Strategy: {strategy}\")\n",
    "        print(f\"   ğŸ“Š Unique values: {unique_count}\")\n",
    "        \n",
    "        if strategy == \"Label Encoding\":\n",
    "            # Binary or ordinal variables\n",
    "            le = LabelEncoder()\n",
    "            non_null_mask = df_encoded[col].notna()\n",
    "            df_encoded.loc[non_null_mask, f\"{col}_label\"] = le.fit_transform(df_encoded.loc[non_null_mask, col])\n",
    "            \n",
    "            encoding_info[col] = {\n",
    "                'strategy': 'label_encoding',\n",
    "                'encoder': le,\n",
    "                'new_columns': [f\"{col}_label\"]\n",
    "            }\n",
    "            print(f\"   âœ… Created: {col}_label\")\n",
    "            \n",
    "        elif strategy == \"One-Hot Encoding\":\n",
    "            # Low cardinality variables\n",
    "            dummies = pd.get_dummies(df_encoded[col], prefix=col, dummy_na=False)\n",
    "            for dummy_col in dummies.columns:\n",
    "                df_encoded[dummy_col] = dummies[dummy_col]\n",
    "            \n",
    "            encoding_info[col] = {\n",
    "                'strategy': 'one_hot_encoding',\n",
    "                'new_columns': dummies.columns.tolist()\n",
    "            }\n",
    "            print(f\"   âœ… Created: {len(dummies.columns)} dummy variables\")\n",
    "            \n",
    "        elif strategy == \"Frequency Encoding\":\n",
    "            # Medium cardinality variables\n",
    "            freq_map = df_encoded[col].value_counts().to_dict()\n",
    "            df_encoded[f\"{col}_freq\"] = df_encoded[col].map(freq_map)\n",
    "            \n",
    "            # Also create label encoding\n",
    "            le = LabelEncoder()\n",
    "            non_null_mask = df_encoded[col].notna()\n",
    "            df_encoded.loc[non_null_mask, f\"{col}_label\"] = le.fit_transform(df_encoded.loc[non_null_mask, col])\n",
    "            \n",
    "            encoding_info[col] = {\n",
    "                'strategy': 'frequency_encoding',\n",
    "                'frequency_map': freq_map,\n",
    "                'encoder': le,\n",
    "                'new_columns': [f\"{col}_freq\", f\"{col}_label\"]\n",
    "            }\n",
    "            print(f\"   âœ… Created: {col}_freq, {col}_label\")\n",
    "            \n",
    "        elif strategy == \"Label + Frequency\":\n",
    "            # High cardinality variables\n",
    "            # Frequency encoding\n",
    "            freq_map = df_encoded[col].value_counts().to_dict()\n",
    "            df_encoded[f\"{col}_freq\"] = df_encoded[col].map(freq_map)\n",
    "            \n",
    "            # Normalized frequency\n",
    "            total_count = df_encoded[col].value_counts().sum()\n",
    "            df_encoded[f\"{col}_freq_norm\"] = df_encoded[f\"{col}_freq\"] / total_count\n",
    "            \n",
    "            # Label encoding\n",
    "            le = LabelEncoder()\n",
    "            non_null_mask = df_encoded[col].notna()\n",
    "            df_encoded.loc[non_null_mask, f\"{col}_label\"] = le.fit_transform(df_encoded.loc[non_null_mask, col])\n",
    "            \n",
    "            encoding_info[col] = {\n",
    "                'strategy': 'label_and_frequency',\n",
    "                'frequency_map': freq_map,\n",
    "                'encoder': le,\n",
    "                'new_columns': [f\"{col}_freq\", f\"{col}_freq_norm\", f\"{col}_label\"]\n",
    "            }\n",
    "            print(f\"   âœ… Created: {col}_freq, {col}_freq_norm, {col}_label\")\n",
    "    \n",
    "    return df_encoded, encoding_info\n",
    "\n",
    "# Apply encoding to all tables\n",
    "encoded_dataframes = {}\n",
    "all_encoding_info = {}\n",
    "\n",
    "for table_name, df in normalized_dataframes.items():\n",
    "    analysis = categorical_analysis.get(table_name, {})\n",
    "    encoded_df, encoding_info = encode_categorical_variables(df, table_name, analysis)\n",
    "    encoded_dataframes[table_name] = encoded_df\n",
    "    all_encoding_info[table_name] = encoding_info\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Categorical encoding completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08df7144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CATEGORICAL CLEANING VALIDATION\n",
      "============================================================\n",
      "ğŸ“Š CATEGORICAL CLEANING SUMMARY:\n",
      "                 Table  Original_Categorical  New_Encoded_Cols  Encoding_Strategies  Final_Rows\n",
      "details_adventure_gear                     6                17                    6         106\n",
      "   details_magic_items                     6                16                    6         199\n",
      "       details_weapons                     8                19                    8          37\n",
      "         details_armor                     8                34                    8          13\n",
      "       details_potions                     5                12                    5          22\n",
      "       details_poisons                     5                13                    5          16\n",
      "          all_products                     4                14                    4         393\n",
      "             customers                     5                11                    5        1423\n",
      "                 sales                     6                13                    6       54126\n",
      "\n",
      "ğŸ¯ OVERALL RESULTS:\n",
      "   ğŸ“Š Original categorical columns: 53\n",
      "   ğŸ“Š New encoded columns created: 149\n",
      "   ğŸ“Š Encoding expansion ratio: 2.81x\n",
      "\n",
      "ğŸ” DATA INTEGRITY CHECK:\n",
      "   âœ… details_adventure_gear: Row count preserved (106 rows)\n",
      "   âœ… details_magic_items: Row count preserved (199 rows)\n",
      "   âœ… details_weapons: Row count preserved (37 rows)\n",
      "   âœ… details_armor: Row count preserved (13 rows)\n",
      "   âœ… details_potions: Row count preserved (22 rows)\n",
      "   âœ… details_poisons: Row count preserved (16 rows)\n",
      "   âœ… all_products: Row count preserved (393 rows)\n",
      "   âœ… customers: Row count preserved (1,423 rows)\n",
      "   âœ… sales: Row count preserved (54,126 rows)\n",
      "\n",
      "ğŸ‰ All data integrity checks passed!\n",
      "\n",
      "ğŸ’¾ Saved encoded dataframes to data_intermediate/05_encoded_dataframes.pkl\n",
      "âœ… Saved encoding info to data_intermediate/05_encoding_info.pkl\n",
      "\n",
      "ğŸ¯ CATEGORICAL CLEANING PHASE COMPLETE!\n",
      "   â¡ï¸ Next: Run 06_numerical_variables_cleaning.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Validate and summarize results\n",
    "print(\"âœ… CATEGORICAL CLEANING VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create summary\n",
    "summary_data = []\n",
    "total_original_categorical = 0\n",
    "total_new_encoded = 0\n",
    "\n",
    "for table_name in dataframes.keys():\n",
    "    original_categorical = len(dataframes[table_name].select_dtypes(include=['object']).columns)\n",
    "    final_df = encoded_dataframes[table_name]\n",
    "    \n",
    "    # Count new encoded columns\n",
    "    encoded_cols = [col for col in final_df.columns \n",
    "                   if any(suffix in col for suffix in ['_label', '_freq', '_norm']) \n",
    "                   or col.startswith(tuple(dataframes[table_name].select_dtypes(include=['object']).columns.tolist() + ['']))]\n",
    "    \n",
    "    encoding_info = all_encoding_info.get(table_name, {})\n",
    "    new_encoded = sum(len(info['new_columns']) for info in encoding_info.values())\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Table': table_name,\n",
    "        'Original_Categorical': original_categorical,\n",
    "        'New_Encoded_Cols': new_encoded,\n",
    "        'Encoding_Strategies': len(encoding_info),\n",
    "        'Final_Rows': len(final_df)\n",
    "    })\n",
    "    \n",
    "    total_original_categorical += original_categorical\n",
    "    total_new_encoded += new_encoded\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"ğŸ“Š CATEGORICAL CLEANING SUMMARY:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nğŸ¯ OVERALL RESULTS:\")\n",
    "print(f\"   ğŸ“Š Original categorical columns: {total_original_categorical}\")\n",
    "print(f\"   ğŸ“Š New encoded columns created: {total_new_encoded}\")\n",
    "print(f\"   ğŸ“Š Encoding expansion ratio: {total_new_encoded/max(1, total_original_categorical):.2f}x\")\n",
    "\n",
    "# Data integrity check\n",
    "print(f\"\\nğŸ” DATA INTEGRITY CHECK:\")\n",
    "all_checks_passed = True\n",
    "for table_name in dataframes.keys():\n",
    "    original_rows = len(dataframes[table_name])\n",
    "    final_rows = len(encoded_dataframes[table_name])\n",
    "    \n",
    "    if original_rows == final_rows:\n",
    "        print(f\"   âœ… {table_name}: Row count preserved ({final_rows:,} rows)\")\n",
    "    else:\n",
    "        print(f\"   âŒ {table_name}: Row count changed! {original_rows:,} â†’ {final_rows:,}\")\n",
    "        all_checks_passed = False\n",
    "\n",
    "if all_checks_passed:\n",
    "    print(f\"\\nğŸ‰ All data integrity checks passed!\")\n",
    "\n",
    "# Save results\n",
    "with open('data_intermediate/05_encoded_dataframes.pkl', 'wb') as f:\n",
    "    pickle.dump(encoded_dataframes, f)\n",
    "print(f\"\\nğŸ’¾ Saved encoded dataframes to data_intermediate/05_encoded_dataframes.pkl\")\n",
    "\n",
    "with open('data_intermediate/05_encoding_info.pkl', 'wb') as f:\n",
    "    pickle.dump(all_encoding_info, f)\n",
    "print(f\"âœ… Saved encoding info to data_intermediate/05_encoding_info.pkl\")\n",
    "\n",
    "print(f\"\\nğŸ¯ CATEGORICAL CLEANING PHASE COMPLETE!\")\n",
    "print(f\"   â¡ï¸ Next: Run 06_numerical_variables_cleaning.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44d607",
   "metadata": {},
   "source": [
    "## ğŸ‰ Phase 5 Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "- âœ… Analyzed categorical variable patterns and cardinality\n",
    "- âœ… Normalized text data (case, spacing, punctuation)\n",
    "- âœ… Consolidated similar categories and handled rare values\n",
    "- âœ… Applied optimal encoding strategies based on variable characteristics\n",
    "- âœ… Created ML-compatible categorical features\n",
    "\n",
    "**Encoding Strategies Applied:**\n",
    "- **Label Encoding**: For binary and ordinal variables\n",
    "- **One-Hot Encoding**: For low cardinality nominal variables\n",
    "- **Frequency Encoding**: For medium cardinality variables\n",
    "- **Combined Encoding**: For high cardinality variables\n",
    "\n",
    "**Next Steps:**\n",
    "- Run `06_numerical_variables_cleaning.ipynb` to clean and optimize numerical variables\n",
    "\n",
    "**Data Files Created:**\n",
    "- `data_intermediate/05_encoded_dataframes.pkl` - DataFrames with encoded categorical variables\n",
    "- `data_intermediate/05_encoding_info.pkl` - Detailed encoding strategy information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
